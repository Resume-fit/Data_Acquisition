{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2dZY6dyLCv4H1XReRDTmf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install selenium\n","!pip install pytesseract\n","!apt-get update\n","!apt install tesseract-ocr-kor\n","\n","# (최초 1회)\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver '/content/drive/MyDrive/Colab Notebooks'\n","!pip install chromedriver-autoinstaller"],"metadata":{"id":"TqklVbhWCApJ","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from selenium import webdriver\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.common.by import By\n","import sys\n","from selenium.webdriver.common.keys import Keys\n","import urllib.request\n","import os\n","from urllib.request import urlretrieve\n","import time\n","import pandas as pd\n","import chromedriver_autoinstaller\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","import pytesseract\n","from urllib.parse import urljoin\n","import re\n","\n","\n","chrome_path = \"/content/drive/MyDrive/Colab Notebooks/chromedriver\"\n","\n","sys.path.insert(0,chrome_path)\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless') # ensure GUI is off\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')  # set path to chromedriver as per your configuration\n","chrome_options.add_argument('lang=ko_KR') # 한국어\n","\n","chrome_options.add_argument(\n","    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n","    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n","    \"Chrome/117.0.0.0 Safari/537.36\"\n",")\n","\n","chromedriver_autoinstaller.install()  # set the target URL\n","\n","url = \"https://www.google.com/\"  # set up the webdriver\n","\n","driver = webdriver.Chrome(options=chrome_options)"],"metadata":{"id":"zUtvNwDsBjW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def define_info(text):\n","    completion = client.chat.completions.create(\n","      extra_headers={},\n","      extra_body={},\n","      model=\"meta-llama/llama-4-maverick\",\n","      messages=[\n","        {\n","          \"role\": \"user\",\n","          \"content\": [\n","            {\n","              \"type\": \"text\",\n","              \"text\": f\"\"\"\n","                        다음은 기업의 채용 공고 상세 내용 원본 텍스트입니다:\n","\n","                        ========================\n","                        {text}\n","                        ========================\n","\n","                        작업 목표:\n","                        주어진 원본 텍스트를 읽고 아래 여섯 개 항목을 **반드시 유효한 JSON 객체 하나**로만 출력하세요. 출력 외에 어떤 추가 문장, 설명, 주석도 허용하지 않습니다.\n","\n","                        요구 출력 형식(엄격):\n","                        {{\n","                          \"주요업무\": [ \"<주요업무 항목1>\", \"<주요업무 항목2>\", ... ],\n","                          \"자격요건\": [ \"<자격요건 항목1>\", \"<자격요건 항목2>\", ... ],\n","                          \"우대사항\": [ \"<우대사항 항목1>\", \"<우대사항 항목2>\", ... ],\n","                          \"자격요건 키워드\": [ \"<기술스택/툴/프레임워크1>\", \"<기술스택2>\", ... ],\n","                          \"우대사항 키워드\": [ \"<기술스택/툴/프레임워크1>\", \"<기술스택2>\", ... ],\n","                          \"직군\": \"<직군 단일값>\"\n","                        }}\n","\n","                        출력 규칙(꼭 지키세요):\n","                        1. 출력은 **오직** 위의 JSON 하나만. 다른 텍스트(설명, 안내문, 예시 등) 절대 넣지 마세요.\n","                        2. 키 이름은 정확히 \"주요업무\", \"자격요건\", \"우대사항\", \"자격요건 키워드\", \"우대사항 키워드\", \"직군\"으로 사용하세요(대소문자 및 공백까지 동일).\n","                        3. \"주요업무\", \"자격요건\", \"우대사항\"의 값은 **문자열 배열**이어야 합니다. 각 배열 원소는 원문에서 추출한 핵심 문장(짧은 문장 또는 핵심 구)으로 만드세요. 항목이 여러 개면 각각 별도의 문자열로 나누세요.\n","                        4. \"자격요건 키워드\"와 \"우대사항 키워드\"는 각각 해당 섹션(자격요건, 우대사항)에서 **언급된 기술 스택·프레임워크·언어·툴·클라우드·DB·라이브러리 등**만을 추출해 **간결한 기술명**으로 나열한 문자열 배열이어야 합니다. 예: \"Python\", \"Java\", \"Spring\", \"Django\", \"PyTorch\", \"TensorFlow\", \"AWS\", \"GCP\", \"MySQL\" 등. 소프트스킬(커뮤니케이션, 팀워크 등)이나 경험 연차 등은 포함하지 마세요.\n","                        5. 키워드 추출 규칙:\n","                          - 각 키워드는 중복 없이 한 번만 포함하세요(중복 제거).\n","                          - 가능한 경우 널리 쓰이는 약어/표준명(예: AWS, SQL, React) 형태로 표기하세요. 원문에 특정 표기가 있을 경우 그 표기를 그대로 사용해도 됩니다.\n","                          - 복합 기술표현(예: \"Java + Spring\")은 가능한 한 개별 키워드로 분리해서 [\"Java\",\"Spring\"]으로 만드세요.\n","                        6. 만약 원문에서 해당 항목(주요업무/자격요건/우대사항)이 명확히 존재하지 않거나 찾을 수 없으면 그 키의 값은 빈 배열 `[]`로 하세요. 키워드 필드도 마찬가지로 기술이 없으면 `[]`로 하세요.\n","                        7. \"직군\" 값은 아래 제공된 **채용공고분류 목록** 중에서 **가장 연관있는 하나**를 정확한 항목 이름(띄어쓰기/구두점 동일)으로 출력하세요. **단,** \"IT개발ㆍ데이터\" 관련 채용공고가 아니라면 `\"직군\"` 값에 문자열 `\"None\"`을 반드시 출력하세요(즉 IT개발ㆍ데이터인 경우에만 분류명을 출력하고, 그 외 모든 경우는 \"None\"으로 표기).\n","                          채용공고분류 목록:\n","                          [프론트엔드, 백엔드, 데이터, AI, 네트워크, 보안, 프로젝트관리, 세일즈, 로봇, 게임, QA, 기타]\n","                        8. JSON 출력은 반드시 **유효한 JSON** (파싱 가능한) 이어야 하며, 모든 문자열은 큰따옴표 `\"`로 감싸야 합니다.\n","                        9. 각 배열 원소(문자열)는 불필요한 기호나 불완전한 문장 대신, 파싱/분석하기 쉬운 **간결한 문장 또는 핵심 구**로 적어주세요(권장 200자 이내).\n","                        10. 절대 예시(JSON 포함)나 응답 포맷 설명을 결과 출력에 포함하지 마세요 — 오직 결과 JSON만 반환하세요.\n","                        11. 기술 키워드는 \"자격요건\"과 \"우대사항\" 섹션에서 각각 별도로 추출하되 **한 단어로 표현되는 기술명(예: Python, Java, Spring, AWS, MySQL 등)**만 포함하고 \"영어 능력 우수\"처럼 소프트스킬이나 문장형 표현은 제외하세요; 어떤 기술이 두 섹션에 모두 언급되면 두 배열에 모두 포함하되 각 배열 내에서만 중복을 제거합니다.\n","                        12. 최종 출력 전에 내부적으로 다음을 확인하세요:\n","                          - 모든 키가 존재하는가? (존재하지 않으면 빈 배열 또는 \"None\"으로 채움)\n","                          - JSON이 파싱 가능한가?\n","                          - \"직군\"이 IT개발ㆍ데이터가 아닌 경우 정확히 \"None\" 문자열을 출력하는가?\n","                        이제 원문 텍스트 `{text}`를 분석하고 위 규칙을 준수하여 결과 JSON만 출력하세요.\n","                        \"\"\"\n","            }\n","          ]\n","        }\n","      ]\n","    )\n","    return(completion.choices[0].message.content)"],"metadata":{"id":"zxAxpy21CMwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filtering(text):\n","    completion = client.chat.completions.create(\n","      extra_headers={},\n","      extra_body={},\n","      model=\"meta-llama/llama-4-maverick\",\n","      messages=[\n","        {\n","          \"role\": \"user\",\n","          \"content\": [\n","            {\n","              \"type\": \"text\",\n","              \"text\": f\"\"\"\n","                        다음은 기업의 채용 공고 제목 텍스트입니다:\n","\n","                        ========================\n","                        {text}\n","                        ========================\n","\n","                        채용공고 제목만 읽고 \"IT개발·데이터\" 직군의 채용공고인지 판별해주세요.\n","                        맞으면 YES, 아니면 NO만 출력해주세요.\n","                        설명이나 다른 말은 하지 말아주세요.\n","                        \"\"\"\n","            }\n","          ]\n","        }\n","      ]\n","    )\n","    return(completion.choices[0].message.content)"],"metadata":{"id":"C-35nxt8zkIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crawl_job(url):\n","    res = requests.get(url, headers=headers)\n","    if res.status_code != 200:\n","        return None\n","\n","    # 크롤링할 URL\n","    driver.get(url)\n","\n","    # 페이지 로딩 대기 (필요 시 WebDriverWait 권장)\n","    time.sleep(2)\n","\n","    # 페이지 소스 가져오기\n","    html = driver.page_source\n","\n","    soup = BeautifulSoup(html, \"html.parser\")\n","\n","    # 지원 마감 체크\n","    if('마감된 공고입니다' in str(soup) or '헤드헌팅 채용정보 보기' in str(soup)): return None\n","\n","    # 공고 이름, 회사명, 위치\n","    company = soup.find(\"h2\", class_=\"Typography_variant_size20__344nw24 Typography_weight_medium__344nw2d Typography_color_gray900__344nw2l Typography_underline__344nw212\").get_text(strip=True)\n","    title = soup.find(\"h1\", class_=\"Typography_variant_size28__344nw20 Typography_weight_bold__344nw2c Typography_color_gray900__344nw2l _1ycqh5m5 _1ycqh5m7\").get_text(strip=True)\n","    try:\n","      place = soup.select_one('body > main > div:nth-child(6) > div:nth-child(2) > div > div > div:nth-child(2) > div > div:nth-child(6) > div > div > span').get_text(strip=True)\n","    except:\n","      place = ''\n","\n","    # 경력 정보\n","    try:\n","      career = soup.select_one('body > main > div:nth-child(6) > div:nth-child(2) > div > div > div:nth-child(2) > div > div:nth-child(2) > div').get_text(strip=True)\n","    except:\n","      career = ''\n","\n","    driver.switch_to.frame(0)\n","    temp = driver.page_source\n","\n","    soup = BeautifulSoup(temp, \"html.parser\")\n","\n","    # 상세 내용\n","    text = soup.get_text(separator=\"\\n\", strip=True)\n","    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n","    clean_text = \"\\n\".join(lines)\n","\n","    base_url = \"https://imgs.jobkorea.co.kr\"\n","    imgs = soup.find_all(\"img\")\n","    img_urls = [img[\"src\"] for img in imgs if img.get(\"src\")]\n","    absolute_urls = [urljoin(base_url, src) for src in img_urls]\n","    text_from_images = []\n","    for img_url in absolute_urls:\n","        resp = requests.get(img_url, headers=headers)\n","        img = Image.open(BytesIO(resp.content))\n","        raw_text = pytesseract.image_to_string(img, lang=\"kor+eng\")\n","        text_from_images.append(\" \".join(raw_text.split()))\n","    full_text = clean_text + \"\\n\" + \"\\n\".join(text_from_images)\n","\n","    for cnt in range(5):\n","      try:\n","        ans = filtering(title)\n","        if(ans.lower()=='no'): break\n","        temp = define_info(full_text)\n","        print(1)\n","        s = temp.strip()\n","        s = re.sub(r\"^```[^\\n]*\\n\", \"\", s)\n","        s = re.sub(r\"\\n```$\", \"\", s)\n","        data = json.loads(s)\n","        break\n","      except:\n","        continue\n","\n","    if(cnt==4): print('Something Wrong'); return None\n","\n","    try:\n","      return {\n","          \"회사\": company,\n","          \"근무지\": place,\n","          \"고용형태\": career,\n","          \"모집명\": title,\n","          \"주요업무\": data['주요업무'],\n","          \"자격요건\": data['자격요건'],\n","          \"우대사항\": data['우대사항'],\n","          \"자격요건 키워드\": data['자격요건 키워드'],\n","          \"우대사항 키워드\": data['우대사항 키워드'],\n","          \"직군\": data['직군'],\n","          \"URL\": url\n","      }\n","    except:\n","      return None"],"metadata":{"id":"TFfYepWJCQXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup, Comment\n","import pandas as pd\n","from time import sleep\n","from openai import OpenAI\n","import json\n","\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","\n","# 마지막 공고 번호 찾기\n","last_job_id = None\n","for test_id in range(47736800, 0, -1):\n","    url = f\"https://www.jobkorea.co.kr/Recruit/GI_Read/{test_id}\"\n","    res = requests.get(url, headers=headers)\n","    if res.status_code != 200:\n","        continue\n","\n","    last_job_id = test_id\n","    print(f\"마지막 공고 번호 발견: {last_job_id}\")\n","    break\n","    sleep(0.05)\n","\n","if last_job_id is None:\n","    raise ValueError(\"마지막 공고 번호를 찾지 못했습니다.\")\n","\n","# 마지막 번호부터 1000 개 크롤링\n","start_id = max(last_job_id - 24, 1)\n","all_jobs = []\n","\n","client = OpenAI(\n","      base_url=\"https://openrouter.ai/api/v1\",\n","      api_key=\"KEY\",\n","      )\n","\n","for job_id in range(start_id, last_job_id + 1):\n","    url = f\"https://www.jobkorea.co.kr/Recruit/GI_Read/{job_id}\"\n","    print(f\"크롤링 중: {url}\")\n","    job = crawl_job(url)\n","    if job:\n","        all_jobs.append(job)\n","    sleep(0.1)  # 서버 과부하 방지\n","\n","\n","# ===============================================\n","\n","# 로컬에 CSV 저장\n","# df = pd.DataFrame(all_jobs)\n","# df.to_csv(\"wanted.csv\", index=False, encoding=\"utf-8-sig\")\n","# print(\"CSV 저장 완료!\")\n","\n","# ===============================================\n"],"metadata":{"id":"p8sMoT-yZLp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 드라이브에 CSV 저장\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","file_path = '/content/drive/My Drive/jobkorea.csv'\n","\n","df = pd.DataFrame(all_jobs)\n","df = df[df[\"직군\"]!=\"None\"]\n","df.to_csv(file_path, index=False, encoding='utf-8-sig')\n","\n","print(\"CSV 저장 완료!\")"],"metadata":{"id":"zvzIQ7wMUELw","collapsed":true},"execution_count":null,"outputs":[]}]}